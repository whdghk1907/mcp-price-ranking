# ğŸ“ˆ ìƒìŠ¹ë¥  ìˆœìœ„ MCP ì„œë²„ ê°œë°œ ê³„íšì„œ

## 1. í”„ë¡œì íŠ¸ ê°œìš”

### 1.1 ëª©ì 
í•œêµ­ ì£¼ì‹ì‹œì¥ì˜ ê°€ê²© ë³€ë™ë¥  ê¸°ì¤€ ìƒìœ„/í•˜ìœ„ ì¢…ëª©ì„ ì‹¤ì‹œê°„ìœ¼ë¡œ ì¶”ì í•˜ê³  ë¶„ì„í•˜ëŠ” MCP ì„œë²„ êµ¬ì¶•

### 1.2 ë²”ìœ„
- ìƒìŠ¹ë¥ /í•˜ë½ë¥  ìƒìœ„ ì¢…ëª© ìˆœìœ„
- 52ì£¼ ì‹ ê³ ê°€/ì‹ ì €ê°€ ì¢…ëª©
- ìƒí•œê°€/í•˜í•œê°€ ì¢…ëª© ì¶”ì 
- ê°€ê²© ê¸‰ë“±/ê¸‰ë½ ì•Œë¦¼
- ì—°ì† ìƒìŠ¹/í•˜ë½ ì¢…ëª© ë¶„ì„
- ë³€ë™ì„± ìƒìœ„ ì¢…ëª©
- ê°­ ìƒìŠ¹/í•˜ë½ ì¢…ëª©

### 1.3 ê¸°ìˆ  ìŠ¤íƒ
- **ì–¸ì–´**: Python 3.11+
- **MCP SDK**: mcp-python
- **API Client**: í•œêµ­íˆ¬ìì¦ê¶Œ OpenAPI
- **ë¹„ë™ê¸° ì²˜ë¦¬**: asyncio, aiohttp
- **ë°ì´í„° ê²€ì¦**: pydantic
- **ê¸°ìˆ ì  ë¶„ì„**: TA-Lib, pandas
- **ìºì‹±**: Redis + ë©”ëª¨ë¦¬ ìºì‹œ

## 2. ì„œë²„ ì•„í‚¤í…ì²˜

```
mcp-price-ranking/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ server.py                 # MCP ì„œë²„ ë©”ì¸
â”‚   â”œâ”€â”€ tools/                    # MCP ë„êµ¬ ì •ì˜
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ price_ranking_tools.py    # ê°€ê²© ìˆœìœ„ ë„êµ¬
â”‚   â”‚   â”œâ”€â”€ high_low_tools.py         # ì‹ ê³ ê°€/ì‹ ì €ê°€ ë„êµ¬
â”‚   â”‚   â”œâ”€â”€ limit_tools.py            # ìƒí•œê°€/í•˜í•œê°€ ë„êµ¬
â”‚   â”‚   â””â”€â”€ volatility_tools.py       # ë³€ë™ì„± ë¶„ì„ ë„êµ¬
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ client.py             # API í´ë¼ì´ì–¸íŠ¸
â”‚   â”‚   â”œâ”€â”€ models.py             # ë°ì´í„° ëª¨ë¸
â”‚   â”‚   â””â”€â”€ constants.py          # ìƒìˆ˜ ì •ì˜
â”‚   â”œâ”€â”€ analysis/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ price_analyzer.py    # ê°€ê²© ë¶„ì„ ì—”ì§„
â”‚   â”‚   â”œâ”€â”€ pattern_detector.py  # íŒ¨í„´ ê°ì§€
â”‚   â”‚   â””â”€â”€ alert_manager.py     # ì•Œë¦¼ ê´€ë¦¬
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”œâ”€â”€ cache.py              # ìºì‹œ ê´€ë¦¬
â”‚   â”‚   â”œâ”€â”€ calculator.py         # ê³„ì‚° ìœ í‹¸ë¦¬í‹°
â”‚   â”‚   â”œâ”€â”€ formatter.py          # ë°ì´í„° í¬ë§·íŒ…
â”‚   â”‚   â””â”€â”€ validator.py          # ê²€ì¦ ë¡œì§
â”‚   â”œâ”€â”€ config.py                 # ì„¤ì • ê´€ë¦¬
â”‚   â””â”€â”€ exceptions.py             # ì˜ˆì™¸ ì •ì˜
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_tools.py
â”‚   â”œâ”€â”€ test_analyzer.py
â”‚   â””â”€â”€ test_patterns.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## 3. í•µì‹¬ ê¸°ëŠ¥ ëª…ì„¸

### 3.1 ì œê³µ ë„êµ¬ (Tools)

#### 1) `get_price_change_ranking`
```python
@tool
async def get_price_change_ranking(
    ranking_type: Literal["TOP_GAINERS", "TOP_LOSERS", "MOST_VOLATILE"] = "TOP_GAINERS",
    market: Literal["ALL", "KOSPI", "KOSDAQ"] = "ALL",
    count: int = 20,
    min_price: Optional[int] = None,
    min_volume: Optional[int] = None
) -> dict:
    """
    ê°€ê²© ë³€ë™ë¥  ê¸°ì¤€ ìˆœìœ„ ì¡°íšŒ
    
    Parameters:
        ranking_type: ìˆœìœ„ ìœ í˜• (ìƒìŠ¹/í•˜ë½/ë³€ë™ì„±)
        market: ì‹œì¥ êµ¬ë¶„
        count: ì¡°íšŒí•  ì¢…ëª© ìˆ˜
        min_price: ìµœì†Œ ì£¼ê°€ í•„í„°
        min_volume: ìµœì†Œ ê±°ë˜ëŸ‰ í•„í„°
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "ranking_type": "TOP_GAINERS",
            "market": "ALL",
            "ranking": [
                {
                    "rank": 1,
                    "stock_code": "123456",
                    "stock_name": "ì¢…ëª©ëª…",
                    "current_price": 5670,
                    "previous_close": 4500,
                    "change": 1170,
                    "change_rate": 26.0,
                    "volume": 12345678,
                    "trading_value": 69876543210,
                    "high": 5800,
                    "low": 4550,
                    "open": 4600,
                    "high_rate": 28.89,  # ê³ ê°€ ëŒ€ë¹„ ìƒìŠ¹ë¥ 
                    "volatility": 27.47,  # ì¼ì¤‘ ë³€ë™ì„±
                    "market_cap_change": 234567890000,  # ì‹œì´ ë³€í™”ì•¡
                    "consecutive_days": 3,  # ì—°ì† ìƒìŠ¹ì¼
                    "foreign_net_buy": 12345678900
                },
                ...
            ],
            "summary": {
                "total_stocks": 2345,
                "advancing": 1234,
                "declining": 890,
                "unchanged": 221,
                "average_change_rate": 1.23,
                "median_change_rate": 0.45
            }
        }
    """
```

#### 2) `get_52week_high_low`
```python
@tool
async def get_52week_high_low(
    type: Literal["HIGH", "LOW", "BOTH"] = "BOTH",
    market: Literal["ALL", "KOSPI", "KOSDAQ"] = "ALL",
    count: int = 20,
    breakthrough_only: bool = True  # ì˜¤ëŠ˜ ëŒíŒŒí•œ ì¢…ëª©ë§Œ
) -> dict:
    """
    52ì£¼ ì‹ ê³ ê°€/ì‹ ì €ê°€ ì¢…ëª© ì¡°íšŒ
    
    Parameters:
        type: ì¡°íšŒ ìœ í˜• (ì‹ ê³ ê°€/ì‹ ì €ê°€/ëª¨ë‘)
        market: ì‹œì¥ êµ¬ë¶„
        count: ì¡°íšŒí•  ì¢…ëª© ìˆ˜
        breakthrough_only: ì˜¤ëŠ˜ ëŒíŒŒ ì¢…ëª©ë§Œ í‘œì‹œ
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "high_stocks": [
                {
                    "stock_code": "005930",
                    "stock_name": "ì‚¼ì„±ì „ì",
                    "current_price": 78500,
                    "52week_high": 78500,
                    "52week_high_date": "2024-01-10",
                    "52week_low": 58000,
                    "high_from_low_rate": 35.34,  # ì €ì  ëŒ€ë¹„ ìƒìŠ¹ë¥ 
                    "volume_ratio": 245.6,  # í‰ê·  ê±°ë˜ëŸ‰ ëŒ€ë¹„
                    "days_since_low": 156,
                    "sector": "ë°˜ë„ì²´",
                    "market_cap": 468923450000000,
                    "foreign_ownership": 51.23,
                    "momentum_score": 8.5  # ëª¨ë©˜í…€ ì ìˆ˜ (1-10)
                },
                ...
            ],
            "low_stocks": [
                {
                    "stock_code": "123456",
                    "stock_name": "ì¢…ëª©ëª…",
                    "current_price": 1200,
                    "52week_high": 3500,
                    "52week_low": 1200,
                    "low_from_high_rate": -65.71,  # ê³ ì  ëŒ€ë¹„ í•˜ë½ë¥ 
                    "volume_ratio": 189.3,
                    "days_since_high": 234,
                    "support_level": 1150,  # ì§€ì§€ì„ 
                    "risk_score": 8.2  # ìœ„í—˜ë„ ì ìˆ˜ (1-10)
                },
                ...
            ],
            "statistics": {
                "new_highs_count": 45,
                "new_lows_count": 23,
                "high_low_ratio": 1.96,
                "market_breadth": "POSITIVE"
            }
        }
    """
```

#### 3) `get_limit_stocks`
```python
@tool
async def get_limit_stocks(
    limit_type: Literal["UPPER", "LOWER", "BOTH"] = "BOTH",
    market: Literal["ALL", "KOSPI", "KOSDAQ"] = "ALL",
    include_history: bool = True
) -> dict:
    """
    ìƒí•œê°€/í•˜í•œê°€ ì¢…ëª© ì¡°íšŒ
    
    Parameters:
        limit_type: ìƒí•œê°€/í•˜í•œê°€ êµ¬ë¶„
        market: ì‹œì¥ êµ¬ë¶„
        include_history: ìµœê·¼ ì´ë ¥ í¬í•¨ ì—¬ë¶€
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "upper_limit": [
                {
                    "stock_code": "123456",
                    "stock_name": "ì¢…ëª©ëª…",
                    "current_price": 5670,
                    "limit_price": 5670,
                    "hit_time": "09:32:15",  # ìƒí•œê°€ ë„ë‹¬ ì‹œê°
                    "volume_at_limit": 2345678,
                    "buy_orders": 12345678,  # ë§¤ìˆ˜ ì”ëŸ‰
                    "sell_orders": 0,
                    "consecutive_limits": 2,  # ì—°ì† ìƒí•œê°€ ì¼ìˆ˜
                    "recent_limits": [  # ìµœê·¼ 30ì¼ ìƒí•œê°€ ì´ë ¥
                        {"date": "2024-01-09", "type": "UPPER"},
                        {"date": "2024-01-08", "type": "UPPER"}
                    ],
                    "unlock_probability": 15.3,  # ìƒí•œê°€ í•´ì œ í™•ë¥ 
                    "theme": ["2ì°¨ì „ì§€", "ì „ê¸°ì°¨"]  # ê´€ë ¨ í…Œë§ˆ
                },
                ...
            ],
            "lower_limit": [...],
            "summary": {
                "upper_count": 12,
                "lower_count": 3,
                "upper_unlock_count": 2,  # ì¥ì¤‘ í•´ì œ
                "lower_unlock_count": 1,
                "market_sentiment": "VERY_BULLISH"
            }
        }
    """
```

#### 4) `get_consecutive_moves`
```python
@tool
async def get_consecutive_moves(
    move_type: Literal["UP", "DOWN"] = "UP",
    min_days: int = 3,
    market: Literal["ALL", "KOSPI", "KOSDAQ"] = "ALL",
    count: int = 20
) -> dict:
    """
    ì—°ì† ìƒìŠ¹/í•˜ë½ ì¢…ëª© ì¡°íšŒ
    
    Parameters:
        move_type: ìƒìŠ¹/í•˜ë½ êµ¬ë¶„
        min_days: ìµœì†Œ ì—°ì†ì¼ìˆ˜
        market: ì‹œì¥ êµ¬ë¶„
        count: ì¡°íšŒí•  ì¢…ëª© ìˆ˜
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "move_type": "UP",
            "stocks": [
                {
                    "stock_code": "005930",
                    "stock_name": "ì‚¼ì„±ì „ì",
                    "consecutive_days": 5,
                    "total_change_rate": 12.5,
                    "average_daily_rate": 2.4,
                    "current_price": 78500,
                    "start_price": 69777,
                    "highest_in_period": 78500,
                    "volume_trend": "INCREASING",  # ê±°ë˜ëŸ‰ ì¶”ì„¸
                    "momentum_indicators": {
                        "rsi": 72.5,
                        "macd": "BULLISH",
                        "stochastic": 85.3
                    },
                    "reversal_probability": 68.5,  # ë°˜ì „ ê°€ëŠ¥ì„±
                    "historical_performance": {
                        "avg_days_before_reversal": 6.2,
                        "avg_pullback_after": -4.5
                    }
                },
                ...
            ],
            "market_analysis": {
                "total_consecutive_up": 156,
                "total_consecutive_down": 89,
                "longest_streak": 12,
                "sector_concentration": {
                    "ë°˜ë„ì²´": 23,
                    "2ì°¨ì „ì§€": 18,
                    "ë°”ì´ì˜¤": 15
                }
            }
        }
    """
```

#### 5) `get_gap_stocks`
```python
@tool
async def get_gap_stocks(
    gap_type: Literal["UP", "DOWN", "BOTH"] = "BOTH",
    min_gap_rate: float = 3.0,
    market: Literal["ALL", "KOSPI", "KOSDAQ"] = "ALL",
    count: int = 20
) -> dict:
    """
    ê°­ ìƒìŠ¹/í•˜ë½ ì¢…ëª© ì¡°íšŒ
    
    Parameters:
        gap_type: ê°­ ìƒìŠ¹/í•˜ë½ êµ¬ë¶„
        min_gap_rate: ìµœì†Œ ê°­ ë¹„ìœ¨ (%)
        market: ì‹œì¥ êµ¬ë¶„
        count: ì¡°íšŒí•  ì¢…ëª© ìˆ˜
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "gap_up_stocks": [
                {
                    "stock_code": "123456",
                    "stock_name": "ì¢…ëª©ëª…",
                    "open_price": 5200,
                    "previous_close": 4800,
                    "gap_size": 400,
                    "gap_rate": 8.33,
                    "current_price": 5350,
                    "gap_filled": false,
                    "low_of_day": 5150,
                    "fill_probability": 35.2,  # ê°­ ë©”ìš°ê¸° í™•ë¥ 
                    "volume_at_open": 1234567,
                    "pre_market_news": true,
                    "catalyst": "ì‹¤ì  í˜¸ì¡° ë°œí‘œ",
                    "similar_gaps_history": [
                        {
                            "date": "2023-11-15",
                            "gap_rate": 7.2,
                            "filled_in_days": 3
                        }
                    ]
                },
                ...
            ],
            "gap_down_stocks": [...],
            "statistics": {
                "avg_gap_up_performance": 2.3,  # ê°­ìƒìŠ¹ í›„ í‰ê·  ìˆ˜ìµë¥ 
                "avg_gap_down_performance": -1.8,
                "gap_fill_rate_up": 62.5,  # ê°­ìƒìŠ¹ ë©”ìš°ê¸° ë¹„ìœ¨
                "gap_fill_rate_down": 71.2
            }
        }
    """
```

#### 6) `get_volatility_ranking`
```python
@tool
async def get_volatility_ranking(
    period: Literal["1D", "5D", "20D"] = "1D",
    market: Literal["ALL", "KOSPI", "KOSDAQ"] = "ALL",
    count: int = 20,
    min_price: Optional[int] = 1000
) -> dict:
    """
    ë³€ë™ì„± ìƒìœ„ ì¢…ëª© ì¡°íšŒ
    
    Parameters:
        period: ë³€ë™ì„± ì¸¡ì • ê¸°ê°„
        market: ì‹œì¥ êµ¬ë¶„
        count: ì¡°íšŒí•  ì¢…ëª© ìˆ˜
        min_price: ìµœì†Œ ì£¼ê°€ í•„í„°
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "period": "1D",
            "ranking": [
                {
                    "rank": 1,
                    "stock_code": "123456",
                    "stock_name": "ì¢…ëª©ëª…",
                    "volatility": 8.75,  # ë³€ë™ì„± (%)
                    "high": 5800,
                    "low": 5200,
                    "current_price": 5450,
                    "average_true_range": 285,  # ATR
                    "beta": 1.85,
                    "price_swings": [  # ì£¼ìš” ê°€ê²© ë³€ë™
                        {"time": "10:30", "price": 5800, "type": "HIGH"},
                        {"time": "11:45", "price": 5200, "type": "LOW"},
                        {"time": "14:20", "price": 5750, "type": "PEAK"}
                    ],
                    "volume_volatility": 156.3,  # ê±°ë˜ëŸ‰ ë³€ë™ì„±
                    "suitable_for": ["DAY_TRADING", "SCALPING"],
                    "risk_level": "VERY_HIGH"
                },
                ...
            ],
            "market_volatility": {
                "vix_equivalent": 24.5,
                "average_volatility": 2.34,
                "volatility_trend": "INCREASING",
                "high_volatility_sectors": ["ë°”ì´ì˜¤", "ì—”í„°", "ê²Œì„"]
            }
        }
    """
```

#### 7) `get_price_alerts`
```python
@tool
async def get_price_alerts(
    alert_types: List[str] = ["BREAKOUT", "BREAKDOWN", "UNUSUAL_MOVE"],
    time_window: int = 30,  # ìµœê·¼ Në¶„
    market: Literal["ALL", "KOSPI", "KOSDAQ"] = "ALL"
) -> dict:
    """
    ì‹¤ì‹œê°„ ê°€ê²© ì•Œë¦¼ ì¡°íšŒ
    
    Parameters:
        alert_types: ì•Œë¦¼ ìœ í˜• ë¦¬ìŠ¤íŠ¸
        time_window: ì¡°íšŒ ì‹œê°„ ë²”ìœ„ (ë¶„)
        market: ì‹œì¥ êµ¬ë¶„
    
    Returns:
        {
            "timestamp": "2024-01-10T10:30:00+09:00",
            "alerts": [
                {
                    "alert_id": "20240110103025001",
                    "alert_type": "BREAKOUT",
                    "stock_code": "005930",
                    "stock_name": "ì‚¼ì„±ì „ì",
                    "trigger_time": "10:30:25",
                    "trigger_price": 78500,
                    "breakout_level": 78000,  # ëŒíŒŒ ë ˆë²¨
                    "volume_surge": 325.6,  # ê±°ë˜ëŸ‰ ê¸‰ì¦ë¥ 
                    "strength_score": 8.5,  # ì‹ í˜¸ ê°•ë„
                    "follow_up": {
                        "current_price": 78600,
                        "high_since_alert": 78800,
                        "performance": 1.02
                    },
                    "technical_confirmation": [
                        "VOLUME_BREAKOUT",
                        "RSI_OVERSOLD_BOUNCE",
                        "MOVING_AVERAGE_CROSS"
                    ]
                },
                ...
            ],
            "alert_summary": {
                "total_alerts": 45,
                "by_type": {
                    "BREAKOUT": 15,
                    "BREAKDOWN": 8,
                    "UNUSUAL_MOVE": 22
                },
                "success_rate": {
                    "BREAKOUT": 73.3,
                    "BREAKDOWN": 68.5
                }
            }
        }
    """
```

## 4. ë¶„ì„ ì—”ì§„ êµ¬í˜„

### 4.1 ê°€ê²© ë¶„ì„ ì—”ì§„

```python
# src/analysis/price_analyzer.py
import numpy as np
import pandas as pd
from typing import Dict, List, Tuple, Optional
from datetime import datetime, timedelta
import talib

class PriceAnalyzer:
    """ê°€ê²© ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        self.cache = {}
        self.indicators = {}
    
    async def analyze_price_action(
        self, 
        stock_code: str, 
        price_data: pd.DataFrame
    ) -> Dict:
        """ì¢…í•©ì ì¸ ê°€ê²© ë¶„ì„"""
        
        analysis = {
            "stock_code": stock_code,
            "timestamp": datetime.now(),
            "price_metrics": self._calculate_price_metrics(price_data),
            "technical_indicators": self._calculate_indicators(price_data),
            "patterns": await self._detect_patterns(price_data),
            "support_resistance": self._find_support_resistance(price_data),
            "trend_analysis": self._analyze_trend(price_data),
            "volatility_analysis": self._analyze_volatility(price_data)
        }
        
        # ì¢…í•© ì ìˆ˜ ê³„ì‚°
        analysis["composite_score"] = self._calculate_composite_score(analysis)
        
        return analysis
    
    def _calculate_price_metrics(self, df: pd.DataFrame) -> Dict:
        """ê°€ê²© ê´€ë ¨ ì£¼ìš” ì§€í‘œ ê³„ì‚°"""
        current = df.iloc[-1]
        
        return {
            "current_price": current['close'],
            "change": current['close'] - current['open'],
            "change_rate": ((current['close'] - current['open']) / current['open']) * 100,
            "high_low_spread": ((current['high'] - current['low']) / current['low']) * 100,
            "close_position": (current['close'] - current['low']) / (current['high'] - current['low']) if current['high'] != current['low'] else 0.5,
            "volume_ratio": current['volume'] / df['volume'].rolling(20).mean().iloc[-1] if len(df) > 20 else 1.0,
            "price_momentum": self._calculate_momentum(df),
            "relative_strength": self._calculate_relative_strength(df)
        }
    
    def _calculate_indicators(self, df: pd.DataFrame) -> Dict:
        """ê¸°ìˆ ì  ì§€í‘œ ê³„ì‚°"""
        close = df['close'].values
        high = df['high'].values
        low = df['low'].values
        volume = df['volume'].values
        
        indicators = {}
        
        # ì´ë™í‰ê· 
        if len(close) >= 5:
            indicators['sma_5'] = talib.SMA(close, timeperiod=5)[-1]
        if len(close) >= 20:
            indicators['sma_20'] = talib.SMA(close, timeperiod=20)[-1]
            indicators['bb_upper'], indicators['bb_middle'], indicators['bb_lower'] = talib.BBANDS(close, timeperiod=20)[-1]
            
        # ëª¨ë©˜í…€ ì§€í‘œ
        if len(close) >= 14:
            indicators['rsi'] = talib.RSI(close, timeperiod=14)[-1]
            indicators['cci'] = talib.CCI(high, low, close, timeperiod=14)[-1]
            
        # MACD
        if len(close) >= 26:
            macd, signal, hist = talib.MACD(close, fastperiod=12, slowperiod=26, signalperiod=9)
            indicators['macd'] = macd[-1]
            indicators['macd_signal'] = signal[-1]
            indicators['macd_histogram'] = hist[-1]
            
        # ê±°ë˜ëŸ‰ ì§€í‘œ
        if len(close) >= 20 and len(volume) >= 20:
            indicators['obv'] = talib.OBV(close, volume)[-1]
            indicators['ad'] = talib.AD(high, low, close, volume)[-1]
            
        return indicators
    
    async def _detect_patterns(self, df: pd.DataFrame) -> List[Dict]:
        """ì°¨íŠ¸ íŒ¨í„´ ê°ì§€"""
        patterns = []
        
        # ìº”ë“¤ìŠ¤í‹± íŒ¨í„´
        open_prices = df['open'].values
        high = df['high'].values
        low = df['low'].values
        close = df['close'].values
        
        # Doji
        doji = talib.CDLDOJI(open_prices, high, low, close)
        if doji[-1] != 0:
            patterns.append({
                "type": "DOJI",
                "strength": abs(doji[-1]),
                "position": len(df) - 1
            })
            
        # Hammer
        hammer = talib.CDLHAMMER(open_prices, high, low, close)
        if hammer[-1] != 0:
            patterns.append({
                "type": "HAMMER",
                "strength": abs(hammer[-1]),
                "position": len(df) - 1
            })
            
        # ì¶”ê°€ íŒ¨í„´ë“¤...
        
        return patterns
    
    def _find_support_resistance(self, df: pd.DataFrame) -> Dict:
        """ì§€ì§€/ì €í•­ì„  ì°¾ê¸°"""
        highs = df['high'].values
        lows = df['low'].values
        
        # í”¼ë²— í¬ì¸íŠ¸ ê³„ì‚°
        pivot = (highs[-1] + lows[-1] + df['close'].iloc[-1]) / 3
        
        # ì§€ì§€/ì €í•­ ë ˆë²¨
        r1 = 2 * pivot - lows[-1]
        s1 = 2 * pivot - highs[-1]
        r2 = pivot + (highs[-1] - lows[-1])
        s2 = pivot - (highs[-1] - lows[-1])
        
        return {
            "pivot": pivot,
            "resistance_1": r1,
            "resistance_2": r2,
            "support_1": s1,
            "support_2": s2,
            "key_levels": self._find_key_levels(df)
        }
    
    def _find_key_levels(self, df: pd.DataFrame, window: int = 20) -> List[float]:
        """ì£¼ìš” ê°€ê²©ëŒ€ ì°¾ê¸°"""
        key_levels = []
        
        # ìµœê·¼ ê³ ì /ì €ì 
        recent_high = df['high'].rolling(window).max()
        recent_low = df['low'].rolling(window).min()
        
        # ìì£¼ í„°ì¹˜ëœ ê°€ê²©ëŒ€ ì°¾ê¸°
        price_counts = {}
        for _, row in df.iterrows():
            for price in [row['high'], row['low'], row['close']]:
                rounded_price = round(price, -2)  # 100ì› ë‹¨ìœ„ ë°˜ì˜¬ë¦¼
                price_counts[rounded_price] = price_counts.get(rounded_price, 0) + 1
        
        # ìƒìœ„ 5ê°œ ê°€ê²©ëŒ€
        sorted_levels = sorted(price_counts.items(), key=lambda x: x[1], reverse=True)[:5]
        key_levels = [level[0] for level in sorted_levels]
        
        return sorted(key_levels)
```

### 4.2 íŒ¨í„´ ê°ì§€ê¸°

```python
# src/analysis/pattern_detector.py
from typing import Dict, List, Optional, Tuple
import numpy as np
from dataclasses import dataclass

@dataclass
class Pattern:
    """íŒ¨í„´ ì •ë³´"""
    name: str
    type: str  # BULLISH, BEARISH, NEUTRAL
    confidence: float
    target_price: Optional[float]
    stop_loss: Optional[float]
    description: str

class PatternDetector:
    """ê°€ê²© íŒ¨í„´ ê°ì§€ê¸°"""
    
    def __init__(self):
        self.min_pattern_bars = 5
        
    def detect_all_patterns(self, price_data: pd.DataFrame) -> List[Pattern]:
        """ëª¨ë“  íŒ¨í„´ ê°ì§€"""
        patterns = []
        
        # ë‹¤ì–‘í•œ íŒ¨í„´ ì²´í¬
        patterns.extend(self.detect_breakout_patterns(price_data))
        patterns.extend(self.detect_reversal_patterns(price_data))
        patterns.extend(self.detect_continuation_patterns(price_data))
        patterns.extend(self.detect_chart_patterns(price_data))
        
        # ì‹ ë¢°ë„ ìˆœìœ¼ë¡œ ì •ë ¬
        patterns.sort(key=lambda x: x.confidence, reverse=True)
        
        return patterns
    
    def detect_breakout_patterns(self, df: pd.DataFrame) -> List[Pattern]:
        """ëŒíŒŒ íŒ¨í„´ ê°ì§€"""
        patterns = []
        
        # ë°•ìŠ¤ê¶Œ ëŒíŒŒ
        if len(df) >= 20:
            recent_high = df['high'].iloc[-20:].max()
            recent_low = df['low'].iloc[-20:].min()
            current_close = df['close'].iloc[-1]
            
            # ìƒë‹¨ ëŒíŒŒ
            if current_close > recent_high * 0.98:
                confidence = min((current_close - recent_high) / recent_high * 100, 100)
                patterns.append(Pattern(
                    name="ë°•ìŠ¤ê¶Œ ìƒë‹¨ ëŒíŒŒ",
                    type="BULLISH",
                    confidence=confidence,
                    target_price=recent_high + (recent_high - recent_low),
                    stop_loss=recent_high * 0.97,
                    description=f"20ì¼ ë°•ìŠ¤ê¶Œ ìƒë‹¨ {recent_high:,.0f}ì› ëŒíŒŒ"
                ))
            
            # í•˜ë‹¨ ì´íƒˆ
            elif current_close < recent_low * 1.02:
                confidence = min((recent_low - current_close) / recent_low * 100, 100)
                patterns.append(Pattern(
                    name="ë°•ìŠ¤ê¶Œ í•˜ë‹¨ ì´íƒˆ",
                    type="BEARISH",
                    confidence=confidence,
                    target_price=recent_low - (recent_high - recent_low),
                    stop_loss=recent_low * 1.03,
                    description=f"20ì¼ ë°•ìŠ¤ê¶Œ í•˜ë‹¨ {recent_low:,.0f}ì› ì´íƒˆ"
                ))
        
        # ì‚¼ê°ìˆ˜ë ´ ëŒíŒŒ
        triangle_pattern = self._detect_triangle_breakout(df)
        if triangle_pattern:
            patterns.append(triangle_pattern)
            
        return patterns
    
    def detect_reversal_patterns(self, df: pd.DataFrame) -> List[Pattern]:
        """ë°˜ì „ íŒ¨í„´ ê°ì§€"""
        patterns = []
        
        # ì´ì¤‘ ë°”ë‹¥/ì²œì •
        double_pattern = self._detect_double_pattern(df)
        if double_pattern:
            patterns.append(double_pattern)
            
        # Vì ë°˜ì „
        v_pattern = self._detect_v_reversal(df)
        if v_pattern:
            patterns.append(v_pattern)
            
        return patterns
    
    def _detect_triangle_breakout(self, df: pd.DataFrame) -> Optional[Pattern]:
        """ì‚¼ê°ìˆ˜ë ´ ëŒíŒŒ ê°ì§€"""
        if len(df) < 30:
            return None
            
        # ê³ ì ê³¼ ì €ì ì˜ ìˆ˜ë ´ í™•ì¸
        highs = df['high'].iloc[-30:].values
        lows = df['low'].iloc[-30:].values
        
        # ì¶”ì„¸ì„  ê³„ì‚°
        high_slope = np.polyfit(range(len(highs)), highs, 1)[0]
        low_slope = np.polyfit(range(len(lows)), lows, 1)[0]
        
        # ìˆ˜ë ´ íŒ¨í„´ í™•ì¸
        if abs(high_slope) < abs(low_slope) and high_slope < 0 and low_slope > 0:
            current_close = df['close'].iloc[-1]
            convergence_point = (highs[-1] + lows[-1]) / 2
            
            if current_close > highs[-1] * 0.98:
                return Pattern(
                    name="ìƒìŠ¹ ì‚¼ê°í˜• ëŒíŒŒ",
                    type="BULLISH",
                    confidence=75.0,
                    target_price=convergence_point + (highs[0] - lows[0]),
                    stop_loss=convergence_point * 0.97,
                    description="ì‚¼ê°ìˆ˜ë ´ ìƒë‹¨ ëŒíŒŒ, ìƒìŠ¹ ëª¨ë©˜í…€ í™•ì¸"
                )
                
        return None
```

### 4.3 ì•Œë¦¼ ê´€ë¦¬ì

```python
# src/analysis/alert_manager.py
from typing import Dict, List, Optional
from datetime import datetime, timedelta
from collections import deque
import asyncio

class AlertManager:
    """ì‹¤ì‹œê°„ ì•Œë¦¼ ê´€ë¦¬"""
    
    def __init__(self, max_alerts_per_stock: int = 5):
        self.alerts = deque(maxlen=1000)  # ìµœê·¼ 1000ê°œ ì•Œë¦¼ ìœ ì§€
        self.alert_history = {}  # ì¢…ëª©ë³„ ì•Œë¦¼ ì´ë ¥
        self.max_alerts_per_stock = max_alerts_per_stock
        self.alert_rules = self._initialize_rules()
        
    def _initialize_rules(self) -> Dict:
        """ì•Œë¦¼ ê·œì¹™ ì´ˆê¸°í™”"""
        return {
            "PRICE_SURGE": {
                "threshold": 5.0,  # 5% ì´ìƒ ê¸‰ë“±
                "time_window": 300,  # 5ë¶„ ë‚´
                "priority": "HIGH"
            },
            "VOLUME_SPIKE": {
                "threshold": 300.0,  # í‰ê·  ëŒ€ë¹„ 300%
                "time_window": 600,  # 10ë¶„ ë‚´
                "priority": "MEDIUM"
            },
            "BREAKOUT": {
                "threshold": 20,  # 20ì¼ ê³ ì  ëŒíŒŒ
                "confirmation_volume": 150.0,  # í‰ê·  ê±°ë˜ëŸ‰ 150%
                "priority": "HIGH"
            },
            "GAP_UP": {
                "threshold": 3.0,  # 3% ì´ìƒ ê°­ìƒìŠ¹
                "priority": "MEDIUM"
            },
            "LIMIT_APPROACH": {
                "threshold": 28.0,  # 28% ìƒìŠ¹ (ìƒí•œê°€ ì„ë°•)
                "priority": "VERY_HIGH"
            }
        }
    
    async def check_alerts(
        self, 
        stock_data: Dict,
        historical_data: pd.DataFrame
    ) -> List[Dict]:
        """ì•Œë¦¼ ì¡°ê±´ ì²´í¬"""
        new_alerts = []
        stock_code = stock_data['stock_code']
        
        # ì¢…ëª©ë³„ ì•Œë¦¼ ì œí•œ ì²´í¬
        if not self._can_send_alert(stock_code):
            return []
        
        # ê° ê·œì¹™ë³„ ì²´í¬
        for rule_name, rule_config in self.alert_rules.items():
            if self._check_rule(rule_name, stock_data, historical_data, rule_config):
                alert = self._create_alert(
                    stock_code=stock_code,
                    stock_name=stock_data['stock_name'],
                    alert_type=rule_name,
                    data=stock_data,
                    priority=rule_config['priority']
                )
                new_alerts.append(alert)
                
        # ì•Œë¦¼ ì €ì¥ ë° ì „ì†¡
        for alert in new_alerts:
            await self._process_alert(alert)
            
        return new_alerts
    
    def _check_rule(
        self, 
        rule_name: str, 
        stock_data: Dict,
        historical_data: pd.DataFrame,
        rule_config: Dict
    ) -> bool:
        """ê°œë³„ ê·œì¹™ ì²´í¬"""
        if rule_name == "PRICE_SURGE":
            return self._check_price_surge(stock_data, rule_config)
        elif rule_name == "VOLUME_SPIKE":
            return self._check_volume_spike(stock_data, historical_data, rule_config)
        elif rule_name == "BREAKOUT":
            return self._check_breakout(stock_data, historical_data, rule_config)
        elif rule_name == "GAP_UP":
            return self._check_gap_up(stock_data, rule_config)
        elif rule_name == "LIMIT_APPROACH":
            return self._check_limit_approach(stock_data, rule_config)
        
        return False
    
    def _check_price_surge(self, stock_data: Dict, config: Dict) -> bool:
        """ê¸‰ë“± ì²´í¬"""
        change_rate = stock_data.get('change_rate', 0)
        return change_rate >= config['threshold']
    
    def _check_volume_spike(
        self, 
        stock_data: Dict, 
        historical_data: pd.DataFrame,
        config: Dict
    ) -> bool:
        """ê±°ë˜ëŸ‰ ê¸‰ì¦ ì²´í¬"""
        if len(historical_data) < 20:
            return False
            
        current_volume = stock_data.get('volume', 0)
        avg_volume = historical_data['volume'].iloc[-20:].mean()
        
        if avg_volume > 0:
            volume_ratio = (current_volume / avg_volume) * 100
            return volume_ratio >= config['threshold']
            
        return False
    
    def _create_alert(
        self,
        stock_code: str,
        stock_name: str,
        alert_type: str,
        data: Dict,
        priority: str
    ) -> Dict:
        """ì•Œë¦¼ ìƒì„±"""
        return {
            "alert_id": f"{datetime.now().strftime('%Y%m%d%H%M%S')}{stock_code}",
            "timestamp": datetime.now(),
            "stock_code": stock_code,
            "stock_name": stock_name,
            "alert_type": alert_type,
            "priority": priority,
            "data": data,
            "message": self._generate_alert_message(alert_type, stock_name, data)
        }
    
    def _generate_alert_message(
        self, 
        alert_type: str, 
        stock_name: str, 
        data: Dict
    ) -> str:
        """ì•Œë¦¼ ë©”ì‹œì§€ ìƒì„±"""
        messages = {
            "PRICE_SURGE": f"{stock_name} ê¸‰ë“±! {data.get('change_rate', 0):.1f}% ìƒìŠ¹",
            "VOLUME_SPIKE": f"{stock_name} ê±°ë˜ëŸ‰ í­ì¦! í‰ê·  ëŒ€ë¹„ {data.get('volume_ratio', 0):.0f}%",
            "BREAKOUT": f"{stock_name} ì£¼ìš” ì €í•­ì„  ëŒíŒŒ! í˜„ì¬ê°€ {data.get('current_price', 0):,}ì›",
            "GAP_UP": f"{stock_name} ê°­ìƒìŠ¹ ì‹œì‘! {data.get('gap_rate', 0):.1f}% ê°­",
            "LIMIT_APPROACH": f"{stock_name} ìƒí•œê°€ ì„ë°•! í˜„ì¬ {data.get('change_rate', 0):.1f}% ìƒìŠ¹"
        }
        
        return messages.get(alert_type, f"{stock_name} {alert_type} ì•Œë¦¼")
```

## 5. ìºì‹± ì „ëµ

```python
# src/utils/cache.py
from typing import Dict, Any, Optional, Set
from datetime import datetime, timedelta
import asyncio
from collections import OrderedDict

class PriceRankingCache:
    """ê°€ê²© ìˆœìœ„ ì „ìš© ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_size: int = 10000):
        self.cache = OrderedDict()
        self.max_size = max_size
        self.hot_stocks: Set[str] = set()  # ìì£¼ ì¡°íšŒë˜ëŠ” ì¢…ëª©
        self.cache_stats = {
            "hits": 0,
            "misses": 0,
            "evictions": 0
        }
        
    async def get_or_compute(
        self,
        key: str,
        compute_func,
        ttl: int = 30,  # ê¸°ë³¸ 30ì´ˆ (ì‹¤ì‹œê°„ì„± ì¤‘ìš”)
        is_hot: bool = False
    ) -> Any:
        """ìºì‹œ ì¡°íšŒ ë˜ëŠ” ê³„ì‚°"""
        
        # Hot ë°ì´í„°ëŠ” ë” ê¸´ TTL
        if is_hot or key in self.hot_stocks:
            ttl = ttl * 2
            
        # ìºì‹œ í™•ì¸
        if key in self.cache:
            entry = self.cache[key]
            if entry['expires'] > datetime.now():
                self.cache_stats['hits'] += 1
                # LRU ì—…ë°ì´íŠ¸
                self.cache.move_to_end(key)
                return entry['data']
            else:
                # ë§Œë£Œëœ í•­ëª© ì œê±°
                del self.cache[key]
                
        # ìºì‹œ ë¯¸ìŠ¤
        self.cache_stats['misses'] += 1
        
        # ë°ì´í„° ê³„ì‚°
        data = await compute_func()
        
        # ìºì‹œ ì €ì¥
        self._set(key, data, ttl)
        
        # Hot ì¢…ëª© ì¶”ì 
        if self.cache_stats['hits'] > 100:  # 100íšŒ ì´ìƒ ì¡°íšŒ í›„
            hit_rate = self.cache_stats['hits'] / (self.cache_stats['hits'] + self.cache_stats['misses'])
            if hit_rate > 0.8:  # 80% ì´ìƒ íˆíŠ¸ìœ¨
                self.hot_stocks.add(key)
                
        return data
        
    def _set(self, key: str, data: Any, ttl: int):
        """ìºì‹œ ì €ì¥"""
        # í¬ê¸° ì œí•œ í™•ì¸
        while len(self.cache) >= self.max_size:
            # LRU ì œê±°
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
            self.cache_stats['evictions'] += 1
            
        self.cache[key] = {
            'data': data,
            'expires': datetime.now() + timedelta(seconds=ttl),
            'access_count': 0
        }
        
    def invalidate_pattern(self, pattern: str):
        """íŒ¨í„´ ê¸°ë°˜ ìºì‹œ ë¬´íš¨í™”"""
        keys_to_remove = [k for k in self.cache.keys() if pattern in k]
        for key in keys_to_remove:
            del self.cache[key]
            
    def get_hot_stocks(self) -> List[str]:
        """ì¸ê¸° ì¢…ëª© ëª©ë¡ ë°˜í™˜"""
        return list(self.hot_stocks)
```

## 6. ì„±ëŠ¥ ìµœì í™”

```python
# src/utils/calculator.py
import numpy as np
from numba import jit
from typing import Tuple, List
import pandas as pd

class OptimizedCalculator:
    """ìµœì í™”ëœ ê³„ì‚° ìœ í‹¸ë¦¬í‹°"""
    
    @staticmethod
    @jit(nopython=True)
    def calculate_change_rates(
        current_prices: np.ndarray,
        previous_prices: np.ndarray
    ) -> np.ndarray:
        """ë²¡í„°í™”ëœ ë³€í™”ìœ¨ ê³„ì‚°"""
        return ((current_prices - previous_prices) / previous_prices) * 100
    
    @staticmethod
    @jit(nopython=True)
    def find_consecutive_moves(
        prices: np.ndarray,
        min_consecutive: int = 3
    ) -> Tuple[np.ndarray, np.ndarray]:
        """ì—°ì† ìƒìŠ¹/í•˜ë½ ì°¾ê¸° (ìµœì í™”)"""
        n = len(prices)
        up_counts = np.zeros(n, dtype=np.int32)
        down_counts = np.zeros(n, dtype=np.int32)
        
        for i in range(1, n):
            if prices[i] > prices[i-1]:
                up_counts[i] = up_counts[i-1] + 1
                down_counts[i] = 0
            elif prices[i] < prices[i-1]:
                down_counts[i] = down_counts[i-1] + 1
                up_counts[i] = 0
            else:
                up_counts[i] = up_counts[i-1]
                down_counts[i] = down_counts[i-1]
                
        return up_counts, down_counts
    
    @staticmethod
    def calculate_volatility_vectorized(
        high_prices: pd.Series,
        low_prices: pd.Series,
        close_prices: pd.Series,
        period: int = 20
    ) -> pd.Series:
        """ë²¡í„°í™”ëœ ë³€ë™ì„± ê³„ì‚°"""
        # Parkinson ë³€ë™ì„±
        hl_ratio = np.log(high_prices / low_prices)
        volatility = np.sqrt(252 / (4 * np.log(2))) * hl_ratio.rolling(period).std()
        
        return volatility * 100  # í¼ì„¼íŠ¸ë¡œ ë³€í™˜
    
    @staticmethod
    def batch_calculate_indicators(
        stocks_data: List[pd.DataFrame],
        indicator_func,
        **kwargs
    ) -> List[Any]:
        """ë°°ì¹˜ ì§€í‘œ ê³„ì‚°"""
        results = []
        
        # ë³‘ë ¬ ì²˜ë¦¬ ê°€ëŠ¥í•œ ê²½ìš°
        for data in stocks_data:
            result = indicator_func(data, **kwargs)
            results.append(result)
            
        return results
```

## 7. êµ¬í˜„ ì¼ì •

### Phase 1: ê¸°ì´ˆ êµ¬í˜„ (4ì¼)
- [ ] í”„ë¡œì íŠ¸ êµ¬ì¡° ì„¤ì •
- [ ] MCP ì„œë²„ ê¸°ë³¸ ì„¤ì •
- [ ] í•œêµ­íˆ¬ìì¦ê¶Œ API í´ë¼ì´ì–¸íŠ¸ êµ¬í˜„
- [ ] ê¸°ë³¸ ê°€ê²© ìˆœìœ„ ë„êµ¬ êµ¬í˜„

### Phase 2: í•µì‹¬ ê¸°ëŠ¥ (5ì¼)
- [ ] 7ê°œ ì£¼ìš” ë„êµ¬ êµ¬í˜„
- [ ] ê°€ê²© ë¶„ì„ ì—”ì§„ êµ¬í˜„
- [ ] íŒ¨í„´ ê°ì§€ê¸° êµ¬í˜„
- [ ] ì•Œë¦¼ ì‹œìŠ¤í…œ êµ¬í˜„

### Phase 3: ê³ ë„í™” (4ì¼)
- [ ] ê¸°ìˆ ì  ì§€í‘œ í†µí•©
- [ ] ì‹¤ì‹œê°„ ì•Œë¦¼ ìµœì í™”
- [ ] ì„±ëŠ¥ ìµœì í™” (ë²¡í„°í™”, ë³‘ë ¬ì²˜ë¦¬)
- [ ] ìºì‹± ì „ëµ êµ¬í˜„

### Phase 4: í…ŒìŠ¤íŠ¸ ë° ë°°í¬ (2ì¼)
- [ ] ë‹¨ìœ„ í…ŒìŠ¤íŠ¸ ì‘ì„±
- [ ] í†µí•© í…ŒìŠ¤íŠ¸
- [ ] ë¬¸ì„œí™”
- [ ] Docker ë°°í¬ ì¤€ë¹„

## 8. í…ŒìŠ¤íŠ¸ ê³„íš

### 8.1 ë‹¨ìœ„ í…ŒìŠ¤íŠ¸

```python
# tests/test_analyzer.py
import pytest
import pandas as pd
import numpy as np
from src.analysis.price_analyzer import PriceAnalyzer
from src.analysis.pattern_detector import PatternDetector

class TestPriceAnalyzer:
    @pytest.fixture
    def sample_data(self):
        """í…ŒìŠ¤íŠ¸ìš© ìƒ˜í”Œ ë°ì´í„°"""
        dates = pd.date_range('2024-01-01', periods=30, freq='D')
        data = pd.DataFrame({
            'open': np.random.uniform(50000, 51000, 30),
            'high': np.random.uniform(51000, 52000, 30),
            'low': np.random.uniform(49000, 50000, 30),
            'close': np.random.uniform(50000, 51000, 30),
            'volume': np.random.uniform(1000000, 2000000, 30)
        }, index=dates)
        return data
    
    @pytest.mark.asyncio
    async def test_analyze_price_action(self, sample_data):
        """ê°€ê²© ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        analyzer = PriceAnalyzer()
        result = await analyzer.analyze_price_action("005930", sample_data)
        
        assert 'price_metrics' in result
        assert 'technical_indicators' in result
        assert 'patterns' in result
        assert 'composite_score' in result
        
    def test_pattern_detection(self, sample_data):
        """íŒ¨í„´ ê°ì§€ í…ŒìŠ¤íŠ¸"""
        detector = PatternDetector()
        
        # ìƒìŠ¹ ì¶”ì„¸ ë°ì´í„° ìƒì„±
        sample_data['close'] = sample_data['close'] * np.linspace(1, 1.2, 30)
        
        patterns = detector.detect_all_patterns(sample_data)
        assert len(patterns) > 0
        assert all(hasattr(p, 'confidence') for p in patterns)

@pytest.mark.asyncio
async def test_alert_generation():
    """ì•Œë¦¼ ìƒì„± í…ŒìŠ¤íŠ¸"""
    from src.analysis.alert_manager import AlertManager
    
    manager = AlertManager()
    
    stock_data = {
        'stock_code': '005930',
        'stock_name': 'ì‚¼ì„±ì „ì',
        'change_rate': 5.5,
        'volume': 30000000,
        'current_price': 78500
    }
    
    alerts = await manager.check_alerts(stock_data, pd.DataFrame())
    assert any(alert['alert_type'] == 'PRICE_SURGE' for alert in alerts)
```

### 8.2 í†µí•© í…ŒìŠ¤íŠ¸

```python
# tests/test_integration.py
import pytest
from src.server import PriceRankingMCPServer

@pytest.mark.asyncio
async def test_full_ranking_flow():
    """ì „ì²´ ìˆœìœ„ ì¡°íšŒ í”Œë¡œìš° í…ŒìŠ¤íŠ¸"""
    server = PriceRankingMCPServer()
    
    # ìƒìŠ¹ë¥  ìˆœìœ„ ì¡°íšŒ
    result = await server.get_price_change_ranking(
        ranking_type="TOP_GAINERS",
        market="ALL",
        count=10
    )
    
    assert 'ranking' in result
    assert len(result['ranking']) <= 10
    assert all('change_rate' in item for item in result['ranking'])
    
    # ìˆœìœ„ê°€ ì˜¬ë°”ë¥´ê²Œ ì •ë ¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
    rates = [item['change_rate'] for item in result['ranking']]
    assert rates == sorted(rates, reverse=True)

@pytest.mark.asyncio
async def test_real_time_alerts():
    """ì‹¤ì‹œê°„ ì•Œë¦¼ í…ŒìŠ¤íŠ¸"""
    server = PriceRankingMCPServer()
    
    # ì•Œë¦¼ ì¡°íšŒ
    alerts = await server.get_price_alerts(
        alert_types=["BREAKOUT", "UNUSUAL_MOVE"],
        time_window=30
    )
    
    assert 'alerts' in alerts
    assert 'alert_summary' in alerts
```

## 9. ë°°í¬ ë° ìš´ì˜

### 9.1 í™˜ê²½ ì„¤ì •

```bash
# .env íŒŒì¼
KOREA_INVESTMENT_APP_KEY=your_app_key
KOREA_INVESTMENT_APP_SECRET=your_app_secret
CACHE_TTL_SECONDS=30
LOG_LEVEL=INFO
ALERT_WEBHOOK_URL=https://your-webhook-url
MAX_ALERTS_PER_MINUTE=100
UNUSUAL_MOVE_THRESHOLD=5.0
```

### 9.2 Docker ì„¤ì •

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

# ì‹œìŠ¤í…œ ì˜ì¡´ì„± ì„¤ì¹˜
RUN apt-get update && apt-get install -y \
    gcc \
    g++ \
    && rm -rf /var/lib/apt/lists/*

# TA-Lib ì„¤ì¹˜
RUN pip install numpy && \
    pip install TA-Lib

# Python ì˜ì¡´ì„± ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œ ë³µì‚¬
COPY . .

# ì‹¤í–‰
CMD ["python", "-m", "src.server"]
```

### 9.3 Docker Compose ì„¤ì •

```yaml
# docker-compose.yml
version: '3.8'

services:
  mcp-price-ranking:
    build: .
    container_name: mcp-price-ranking
    environment:
      - KOREA_INVESTMENT_APP_KEY=${KOREA_INVESTMENT_APP_KEY}
      - KOREA_INVESTMENT_APP_SECRET=${KOREA_INVESTMENT_APP_SECRET}
      - REDIS_URL=redis://redis:6379
    ports:
      - "8082:8080"
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    depends_on:
      - redis
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data

volumes:
  redis_data:
```

## 10. ëª¨ë‹ˆí„°ë§ ë° ìœ ì§€ë³´ìˆ˜

### 10.1 ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§

```python
# src/utils/monitoring.py
from dataclasses import dataclass
from datetime import datetime
from typing import Dict, List
import asyncio

@dataclass
class RealtimeMetrics:
    """ì‹¤ì‹œê°„ ë©”íŠ¸ë¦­"""
    timestamp: datetime
    active_alerts: int
    ranking_requests_per_minute: int
    average_response_time: float
    cache_hit_rate: float
    hot_stocks: List[str]
    error_rate: float

class RealtimeMonitor:
    """ì‹¤ì‹œê°„ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.metrics_buffer = []
        self.alert_counter = 0
        self.request_counter = 0
        self.response_times = []
        
    async def collect_metrics(self) -> RealtimeMetrics:
        """ë©”íŠ¸ë¦­ ìˆ˜ì§‘"""
        current_time = datetime.now()
        
        # 1ë¶„ê°„ í‰ê·  ê³„ì‚°
        recent_responses = [
            t for t in self.response_times 
            if (current_time - t['timestamp']).seconds < 60
        ]
        
        avg_response_time = (
            sum(r['duration'] for r in recent_responses) / len(recent_responses)
            if recent_responses else 0
        )
        
        metrics = RealtimeMetrics(
            timestamp=current_time,
            active_alerts=self.alert_counter,
            ranking_requests_per_minute=self.request_counter,
            average_response_time=avg_response_time,
            cache_hit_rate=self._calculate_cache_hit_rate(),
            hot_stocks=self._get_hot_stocks(),
            error_rate=self._calculate_error_rate()
        )
        
        self.metrics_buffer.append(metrics)
        
        # ë©”íŠ¸ë¦­ ë¦¬ì…‹
        if len(self.metrics_buffer) > 60:  # 1ì‹œê°„ ë°ì´í„° ìœ ì§€
            self.metrics_buffer = self.metrics_buffer[-60:]
            
        return metrics
    
    async def check_health(self) -> Dict:
        """ì‹œìŠ¤í…œ ê±´ê°• ìƒíƒœ ì²´í¬"""
        metrics = await self.collect_metrics()
        
        health_status = {
            "status": "healthy",
            "issues": []
        }
        
        # ì‘ë‹µ ì‹œê°„ ì²´í¬
        if metrics.average_response_time > 2.0:
            health_status["issues"].append({
                "type": "SLOW_RESPONSE",
                "message": f"í‰ê·  ì‘ë‹µ ì‹œê°„ ì´ˆê³¼: {metrics.average_response_time:.2f}ì´ˆ"
            })
            
        # ì—ëŸ¬ìœ¨ ì²´í¬
        if metrics.error_rate > 0.05:
            health_status["issues"].append({
                "type": "HIGH_ERROR_RATE",
                "message": f"ë†’ì€ ì—ëŸ¬ìœ¨: {metrics.error_rate:.1%}"
            })
            
        # ìºì‹œ íš¨ìœ¨ì„± ì²´í¬
        if metrics.cache_hit_rate < 0.5:
            health_status["issues"].append({
                "type": "LOW_CACHE_HIT",
                "message": f"ë‚®ì€ ìºì‹œ íˆíŠ¸ìœ¨: {metrics.cache_hit_rate:.1%}"
            })
            
        if health_status["issues"]:
            health_status["status"] = "unhealthy"
            
        return health_status
```

### 10.2 ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì„

```python
# src/utils/log_aggregator.py
from collections import defaultdict
from datetime import datetime, timedelta
import json

class LogAggregator:
    """ë¡œê·¸ ì§‘ê³„ ë° ë¶„ì„"""
    
    def __init__(self):
        self.alert_stats = defaultdict(int)
        self.stock_access_count = defaultdict(int)
        self.error_patterns = defaultdict(list)
        
    def aggregate_daily_stats(self, log_file: str) -> Dict:
        """ì¼ë³„ í†µê³„ ì§‘ê³„"""
        stats = {
            "date": datetime.now().date().isoformat(),
            "total_requests": 0,
            "unique_stocks": set(),
            "alert_distribution": {},
            "peak_hours": [],
            "error_summary": {}
        }
        
        hourly_requests = defaultdict(int)
        
        with open(log_file, 'r') as f:
            for line in f:
                try:
                    log_data = json.loads(line)
                    
                    # ìš”ì²­ ìˆ˜ ì§‘ê³„
                    stats["total_requests"] += 1
                    
                    # ì‹œê°„ë³„ ì§‘ê³„
                    hour = datetime.fromisoformat(log_data['timestamp']).hour
                    hourly_requests[hour] += 1
                    
                    # ì¢…ëª©ë³„ ì§‘ê³„
                    if 'stock_code' in log_data:
                        stats["unique_stocks"].add(log_data['stock_code'])
                        self.stock_access_count[log_data['stock_code']] += 1
                        
                    # ì•Œë¦¼ ì§‘ê³„
                    if 'alert_type' in log_data:
                        self.alert_stats[log_data['alert_type']] += 1
                        
                except Exception as e:
                    continue
                    
        # í†µê³„ ì •ë¦¬
        stats["unique_stocks"] = len(stats["unique_stocks"])
        stats["alert_distribution"] = dict(self.alert_stats)
        stats["peak_hours"] = sorted(
            hourly_requests.items(), 
            key=lambda x: x[1], 
            reverse=True
        )[:3]
        
        # ì¸ê¸° ì¢…ëª© TOP 10
        stats["hot_stocks"] = sorted(
            self.stock_access_count.items(),
            key=lambda x: x[1],
            reverse=True
        )[:10]
        
        return stats
```

### 10.3 ì•Œë¦¼ ë° ë³´ê³ 

- ì‹¤ì‹œê°„ ì•Œë¦¼ (Webhook/Slack)
- ì¼ë³„ ë¦¬í¬íŠ¸ ìƒì„±
- ì£¼ê°„ íŠ¸ë Œë“œ ë¶„ì„
- ì´ìƒ íŒ¨í„´ ê°ì§€ ì•Œë¦¼

## 11. ë³´ì•ˆ ê³ ë ¤ì‚¬í•­

### 11.1 API ë³´ì•ˆ
- API í‚¤ ì•”í˜¸í™” ì €ì¥
- Rate limiting (ë¶„ë‹¹ ìš”ì²­ ì œí•œ)
- IP í™”ì´íŠ¸ë¦¬ìŠ¤íŠ¸

### 11.2 ë°ì´í„° ë³´ì•ˆ
- ë¯¼ê° ì •ë³´ ë§ˆìŠ¤í‚¹
- ë¡œê·¸ ë°ì´í„° ì•”í˜¸í™”
- ì •ê¸°ì  ë³´ì•ˆ ê°ì‚¬

### 11.3 ì•Œë¦¼ ë³´ì•ˆ
- Webhook URL ê²€ì¦
- ì•Œë¦¼ ë‚´ìš© í•„í„°ë§
- DDoS ë°©ì§€ ë©”ì»¤ë‹ˆì¦˜

ì´ ê³„íšì„œë¥¼ í†µí•´ ì‹¤ì‹œê°„ì„±ê³¼ ì •í™•ì„±ì„ ê°–ì¶˜ ìƒìŠ¹ë¥  ìˆœìœ„ MCP ì„œë²„ë¥¼ êµ¬ì¶•í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.